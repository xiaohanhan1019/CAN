import torch
from utils.configs import dataset_configs
from ray import tune

model_tune_configs = {
    "CAN": {
        "model": "CAN",
        "front_padding": True,
        "hidden_size": 100,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": 0,
        "n_layers": 2,
        "n_heads": 1,
        "dropout_prob": tune.grid_search([0,0.25,0.5]),
        "n": 0,
        "k": tune.grid_search(
            [[0, 10], [1, 10], [3, 10], [5, 10], [8, 10], [10, 10]]),
        "l": tune.grid_search([20]),
        'threshold': 1e-3,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "SASRec": {
        "model": "SASRec",
        "front_padding": True,
        "hidden_size": 100,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": 0,
        "n_layers": 2,
        "n_heads": 1,
        "dropout_prob": tune.grid_search([0, 0.25, 0.5]),
        "seq_length": tune.grid_search([50]),
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "GRU4Rec": {
        "model": "GRU4Rec",
        "front_padding": False,
        "hidden_size": 100,
        "lr": tune.grid_search([5e-4, 1e-3, 2e-3]),
        "reg": 0,
        "num_layers": 1,
        "dropout_prob": tune.grid_search([0, 0.25,0.5]),
        "seq_length": tune.grid_search([50]),
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "Caser": {
        "model": "Caser",
        "front_padding": False,
        "embedding_size": 100,
        "n_h": tune.grid_search([4, 8]),
        "n_v": tune.grid_search([4]),
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": tune.grid_search([1e-5, 1e-6]),
        "dropout_prob": tune.grid_search([0,0.25, 0.5]),
        "batch_size": 256,
        "epoch": 15,
        "grace_period": 8,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "GCSAN": {
        "model": "GCSAN",
        "front_padding": False,
        "hidden_size": 100,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": tune.grid_search([1e-6, 0]),
        "n_layers": tune.grid_search([2]),
        "n_heads": 1,
        "weight": tune.grid_search([0.6, 0.7, 0.8]),
        "step": 1,
        "dropout_prob": tune.grid_search([0,0.25, 0.5]),
        "batch_size": 256,
        "epoch": 12,
        "grace_period": 8,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "RUM_item": {
        "model": "RUM_item",
        "front_padding": True,
        "embedding_dim": 100,
        "k": tune.grid_search([5, 10, 20]),
        "alpha": tune.grid_search([0.6, 0.8]),
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": tune.grid_search([1e-5, 1e-6, 0]),
        "epoch": 30,
        "grace_period": 20,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "RUM_feature": {
        "model": "RUM_feature",
        "front_padding": True,
        "embedding_dim": 100,
        "k": tune.grid_search([1, 3]),
        "alpha": tune.grid_search([0.6, 0.8]),
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": tune.grid_search([1e-5, 1e-6, 1e-5]),
        "epoch": 10,
        "grace_period": 6,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "SINE": {
        "model": "SINE",
        "front_padding": True,
        "hidden_size": 100,
        "seq_length": 50,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "l": tune.grid_search([100, 500]),
        "k": tune.grid_search([2, 4, 8]),
        "lambda": 0.5,
        "reg": 0,
        "batch_size": 256,
        "epoch": 20,
        "grace_period": 15,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "MIND": {
        "model": "MIND",
        "front_padding": True,
        "hidden_size": 100,
        "seq_length": 50,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "k": tune.grid_search([1, 2, 5, 8]),
        "reg": tune.grid_search([1e-6, 0]),
        "pow": 2,
        "grace_period": 15,
        "epoch": 25,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "ComiRec_DR": {
        "model": "ComiRec_DR",
        "front_padding": True,
        "hidden_size": 100,
        "seq_length": 50,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "k": tune.grid_search([1, 2, 5, 8]),
        "reg": tune.grid_search([1e-5, 1e-6, 0]),
        "grace_period": 30,
        "epoch": 50,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "ComiRec_SA": {
        "model": "ComiRec_SA",
        "front_padding": True,
        "hidden_size": 100,
        "seq_length": 50,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "k": tune.grid_search([5, 8, 12, 20]),
        "reg": tune.grid_search([1e-5, 1e-6, 0]),
        "grace_period": 30,
        "epoch": 35,
        "batch_size": 256,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
    "SHAN": {
        "model": "SHAN",
        "front_padding": True,
        "hidden_size": 100,
        "lr": tune.grid_search([5e-4,1e-3,2e-3]),
        "reg": tune.grid_search([1e-5, 1e-6, 0]),
        "batch_size": 256,
        "short_item_length": tune.grid_search([1,2,5]),
        "seq_length": tune.grid_search([50]),
        "epoch": 30,
        "grace_period": 20,
        "device": torch.device("cuda:0"),
        "verbose": False,
        "report": True
    },
}


def get_tune_config(model='Test', dataset='ml-1m'):
    return dict(dataset_configs[dataset], **model_tune_configs[model])


if __name__ == '__main__':
    print(get_tune_config(model="CAN", dataset='Amazon_Books'))
